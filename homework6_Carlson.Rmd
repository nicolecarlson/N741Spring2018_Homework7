---
title: 'Homework 6: GLM and LM, prediction'
author: "Nicole Carlson."
output:
  word_document: default
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Homework 6

### Background and Information on HELP Dataset

For homework 6, you will be working with the **HELP** (Health Evaluation and Linkage to Primary Care) Dataset.

The HELP Dataset:

* You can learn more about the HELP (Health Evaluation and Linkage to Primary Care) dataset at [https://nhorton.people.amherst.edu/sasr2/datasets.php](https://nhorton.people.amherst.edu/sasr2/datasets.php). This dataset is also used by Ken Kleinman and Nicholas J. Horton for their book "SAS and R: Data Management, Statistical Analysis, and Graphics" (which is another helpful textbook).

* You can download the datasets from their website [https://nhorton.people.amherst.edu/sasr2/datasets.php](https://nhorton.people.amherst.edu/sasr2/datasets.php)

* The original publication is referenced at [https://www.ncbi.nlm.nih.gov/pubmed/12653820?ordinalpos=17&itool=EntrezSystem2.PEntrez.Pubmed.Pubmed_ResultsPanel.Pubmed_DefaultReportPanel.Pubmed_RVDocSum](https://www.ncbi.nlm.nih.gov/pubmed/12653820?ordinalpos=17&itool=EntrezSystem2.PEntrez.Pubmed.Pubmed_ResultsPanel.Pubmed_DefaultReportPanel.Pubmed_RVDocSum)

* The HELP documentation (including all forms/surveys/instruments used) are located at:
    + [https://nhorton.people.amherst.edu/help/](https://nhorton.people.amherst.edu/help/)
    + specifically the details on all BASELINE assessments are located in this PDF [https://nhorton.people.amherst.edu/help/HELP-baseline.pdf](https://nhorton.people.amherst.edu/help/HELP-baseline.pdf)
    + with the follow up time points described in the PDF [https://nhorton.people.amherst.edu/help/HELP-followup.pdf](https://nhorton.people.amherst.edu/help/HELP-followup.pdf)

###Summary of Entire HELP Dataset - Complete Codebook

See complete data descriptions and codebook at [https://melindahiggins2000.github.io/N736Fall2017_HELPdataset/](https://melindahiggins2000.github.io/N736Fall2017_HELPdataset/)

### Variables for Homework 6

For Homework 6, you will focus only on these variables from the HELP dataset:

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(haven)
helpdata <- haven::read_spss("helpmkh.sav")

sub1 <- helpdata %>%
  select(age, female, pss_fr, homeless, 
         pcs, mcs, cesd)

# create a function to get the label
# label output from the attributes() function
getlabel <- function(x) attributes(x)$label
# getlabel(sub1$age)

library(purrr)
ldf <- purrr::map_df(sub1, getlabel) # this is a 1x15 tibble data.frame
# t(ldf) # transpose for easier reading to a 15x1 single column list

# using knitr to get a table of these
# variable names for Rmarkdown
library(knitr)
knitr::kable(t(ldf),
             col.names = c("Variable Label"),
             caption="Use these variables from HELP dataset for Homework 06")

```

## Homework 6 Assignment

**SETUP** Download and run the "loadHELP.R" `R` script (included in this Github repo [https://github.com/melindahiggins2000/N741Spring2018_Homework6](https://github.com/melindahiggins2000/N741Spring2018_Homework6)) to read in the HELP Dataset "helpmkh.sav". This script also pulls out the variables you need and creates the dichotomous variable for depression `cesd_gte16` which you will need for the logistic regression.

After running this R script, you will have a data frame called `h1` you can use to do the rest of your analyses. You can also copy this code into your first R markdown code chunk to get you started on Homework 6.

For Homework 6, you will be looking at depression in these subjects. First, you will be running a model to look at the continuous depression measure - the CESD [Center for Epidemiologic Studies Depression Scale](http://cesd-r.com/) which is a measure of depressive symptoms. Also see the APA details on the CESD at [http://www.apa.org/pi/about/publications/caregivers/practice-settings/assessment/tools/depression-scale.aspx](http://www.apa.org/pi/about/publications/caregivers/practice-settings/assessment/tools/depression-scale.aspx). The CESD can be used to predict actual clinical depression but it is not technically a diagnosis of depression. The CESD scores range from 0 (no depressive symptoms) to 60 (most severe depressive symptoms). You will use the (`cesd`) variable to run a linear regression.

The recommended threshold use to indicate potential clinical depression is for people with scores of 16 or greater. You will then use the variable created using this cutoff (`cesd_gte16`) to perform a similar modeling approach with the variables to predict the probability of clinical depression (using logistic regression).

## Homework 6 Tasks

1. [Model 1] Run a simple linear regression (`lm()`) for `cesd` using the `mcs` variable, which is the mental component quality of life score from the SF36.

```{r}

library(car)
library(stargazer)
h1 <- readRDS("h1.rds")
unajustedCESD <- lm(cesd ~ mcs, data = h1)
summary(unajustedCESD)
```


2. Write the equation of the final fitted model (i.e. what is the intercept and the slope)? Write a sentence describing the model results (interpret the intercept and slope). _NOTE: The `mcs` values range form 0 to 100 where the population norm for "normal mental health quality of life" is considered to be a 50. If you score higher than 50 on the `mcs` you have mental health better than the population and visa versa - if your `mcs` scores are less than 50 then your mental health is considered to be worse than the population norm._

```{r}
plot(cesd ~ mcs, data = h1)
```
Equation for final fitted model: cesd= 53.90 - 0.66 (msc)

Interpretation: The mean cesd score is 53.90 when mcs score is equal to 0.  For each increase in mcs of 1 point, the cesd score decreases by 0.66 points. You can see from the plot above that there is a linear relationship beteween these two variables, and most of the cases in this dataset have mcs scores below the 'normal' level of 50.


3. How much variability in the `cesd` does the `mcs` explain? (what is the R<sup>2</sup>?) Write a sentence describing how well the `mcs` does in predicting the `cesd`.

MCS score explains 46% of the variability in the CESD score.

4. [Model 2] Run a second linear regression model (`lm()`) for the `cesd` putting in all of the other variables: 
    + `age`
    + `female`
    + `pss_fr`
    + `homeless`
    + `pcs`
    + `mcs`
    
    + Print out the model results with the coefficients and tests and model fit statistics.
    
```{r}
ajustedCESD <- lm(cesd ~ ., data = h1)
summary(ajustedCESD)
```
    

5. Which variables are significant in the model? Write a sentence or two describing the impact of these variables for predicting depression scores (HINT: interpret the coefficient terms).

In this adjusted model of cesd, the significant predictors were: female gender, pss_fr, pcs, mcs, and cesd_gte16.

6. Following the example we did in class for the Prestige dataset [https://cdn.rawgit.com/vhertzb/2018week9/2f2ea142/2018week9.html?raw=true](https://cdn.rawgit.com/vhertzb/2018week9/2f2ea142/2018week9.html?raw=true), generate the diagnostic plotss for this model with these 6 predictors (e.g. get the residual plot by variables, the added-variable plots, the Q-Q plot, diagnostic plots). Also run the VIFs to check for multicollinearity issues.

```{r}
scatterplotMatrix(~ cesd + age + female + pss_fr + + homeless + pcs + mcs, span =0.7, data = h1)
```


```{r}
residualPlots(ajustedCESD)
```

```{r}
avPlots(ajustedCESD, id.n=2, id.cex=0.7)
```

```{r}
qqPlot(ajustedCESD, id.n=3)
```

```{r}
outlierTest(ajustedCESD)
```

```{r}
influenceIndexPlot(ajustedCESD, id.n=3)
influencePlot(ajustedCESD, id.n=3)
```

```{r}
ncvTest(ajustedCESD)
vif(ajustedCESD)
```

7. [Model 3] Repeat Model 1 above, except this time run a logistic regression (`glm()`) to predict CESD scores => 16 (using the `cesd_gte16` as the outcome) as a function of `mcs` scores. Show a summary of the final fitted model and explain the coefficients. [**REMEMBER** to compute the Odds Ratios after you get the raw coefficient (betas)].

```{r}
logisticCESD <- glm(cesd_gte16 ~ mcs, data = h1)
summary(logisticCESD)
exp(cbind(OR = coef(logisticCESD), confint(logisticCESD)))
```
In this dataset, mcs is a significant predictor of cesd score of at least 16. The odds ratio of mcs is 0.98, meaning that for every 1 point increase in a person's mcs score, their odds of having a cesd score of at least 16 is decreased by 2%--in other words, their risk of depression (as diagnosed by a score of at least 16 on the CESD) is slightly decreased by having a higher mcs score.



8. Use the `predict()` function like we did in class to predict CESD => 16 and compare it back to the original data. For now, use a cutoff probability of 0.5 - if the probability is > 0.5 consider this to be true and false otherwise. Like we did in class. **REMEMBER** See the R code for the class example at [https://github.com/melindahiggins2000/N741_lecture11_27March2018/blob/master/lesson11_logreg_Rcode.R](https://github.com/melindahiggins2000/N741_lecture11_27March2018/blob/master/lesson11_logreg_Rcode.R)
    + How well did the model correctly predict CESD scores => 16 (indicating depression)? (make the "confusion matrix" and look at the true positives and true negatives versus the false positives and false negatives).
```{r}
h1.predict <- predict(logisticCESD, newdata=h1,
                      type="response")
plot(h1$cesd_gte16, h1.predict)
```

```{r}
table(h1$cesd_gte16, h1.predict > 0.5)
```
Based on this confusion matrix results, the model was pretty good at predicting a cesd score of greater than or equal to 16.  Prediction was that the cesd result would be in the depression range for only 46 cases that were actually not depressed (cesd < 16), while 407 of the guesses were correct.
    
9. Make an ROC curve plot and compute the AUC and explain if this is a good model for predicting depression or not

```{r}
library(ROCR)
p <- predict(logisticCESD, newdata=h1, 
             type="response")
pr <- prediction(p, as.numeric(h1$cesd_gte16))
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf)
abline(a=0, b=1, col="red")

```


```{r}
auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
auc
```
This model, with only one predictor (msc score) did very well at predicting cesd less than 16; 92.3% of true positives were predicted by msc score.

10. Make a plot showing the probability curve - put the `mcs` values on the X-axis and the probability of depression on the Y-axis. Based on this plot, do you think the `mcs` is a good predictor of depression? [**FYI** This plot is also called an "effect plot" is you're using `Rcmdr` to do these analyses.]

```{r}
library(Rcmdr)
plot(allEffects(logisticCESD))
```
Here is the effects plot for this logistic regression. Based on the tight confidence interval and grouping of mcs scores around a cesd_gte16 value of 1 on the plotted line, this plot demonstrates thata mcs scores (especially those between 17 and 33, where there is a clumping of points on the x-axis) appear to be predictive of depression.

My work can be found at github repo: https://github.com/nicolecarlson/N741Spring2018_Homework7


---

**Use R markdown to complete your homework and show all of your code and output in your final report - Turn in a PDF of your report to Canvas. Include a link to your Github repo for Homework 6**

---


